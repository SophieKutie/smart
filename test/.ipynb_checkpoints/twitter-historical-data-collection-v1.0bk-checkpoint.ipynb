{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from tweepy import API as api\n",
    "from tweepy import Cursor\n",
    "import tweepy\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os, sys\n",
    "import pprint\n",
    "import math\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6cf66dd3bd9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#lib_dem = get_hate_terms('./data/lib_dem.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mterms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcons\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mind\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabour\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlib_dem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m '''\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cons' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "get a list of hateful terms. These ae collected from hatebase.org using the hatespeech-vocabulary-collection script \n",
    "stroed in hatespeech-terms.csv file\n",
    "csv_file_name should include the full path to the file\n",
    "the file should be formatted as one column labelled 'term' and as many terms as required\n",
    "\n",
    "term\n",
    "term 1\n",
    "term 2\n",
    "term 3\n",
    "...\n",
    "'''\n",
    "def get_hate_terms(csv_file_name):\n",
    "    terms = pd.read_csv(csv_file_name, encoding='utf')\n",
    "    #terms.sort_values('term', inplace=True)\n",
    "    #print('Before removing duplicated terms: ', terms.count())\n",
    "    terms.drop_duplicates(keep='first', inplace=True)\n",
    "    #print('After removing duplicated terms: ',  terms.count())\n",
    "    return terms['terms'].astype(str).values.tolist()\n",
    "    \n",
    "\n",
    "hate_terms = get_hate_terms('./data/abusive_terms.csv')\n",
    "#cons = get_hate_terms('./data/conservative.csv')\n",
    "#ind = get_hate_terms('./data/independent.csv')\n",
    "#labour =get_hate_terms('./data/labour.csv')\n",
    "#lib_dem = get_hate_terms('./data/lib_dem.csv')\n",
    "\n",
    "terms = hate_terms\n",
    "#cons + ind + labour + lib_dem\n",
    "\n",
    "'''\n",
    "Twitter only accepts n number of terms at a time\n",
    "Use this function if we have a large number of terms so we supply twitter with small list of terms in each API call\n",
    "return randomised list of terms\n",
    "'''\n",
    "def get_list_of_list(list_of_terms, sublist_size):\n",
    "    random_list = random.sample(list_of_terms, len(list_of_terms)) \n",
    "    #print(random_list)\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(random_list), sublist_size):\n",
    "        # Create an index range for l of n items:\n",
    "        yield random_list[i:i+sublist_size]\n",
    " \n",
    "term_list = list(get_list_of_list(terms, 99))\n",
    "print('The number of list terms to be processed: %d'%len(term_list))\n",
    "for terms in term_list:\n",
    "    print(terms)\n",
    "    \n",
    "def get_start_time():\n",
    "    start_time = time.time()\n",
    "    print('started at: ',datetime.fromtimestamp(start_time).strftime(\"%c\"))\n",
    "    return start_time\n",
    "   \n",
    "def get_time_taken(start_time): \n",
    "    end_time = time.time()\n",
    "    print('ended at: ',datetime.fromtimestamp(end_time).strftime(\"%c\"))\n",
    "    total_time_taken = end_time-start_time\n",
    "    total_time_taken = datetime.fromtimestamp(total_time_taken)\n",
    "    print('time taken: ', total_time_taken.strftime('%M'),':',total_time_taken.strftime('%S'), ' seconds')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#from TwitterAPI import TwitterRestPager\n",
    "#from t import TwitterRestPager\n",
    "\n",
    "SEARCH_TERM = 'pizza'\n",
    "GEOCODE = '40,74,10km'\n",
    "cons = get_hate_terms('./data/conservative.csv')\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search, q=SEARCH_TERM, count=100, lang=\"en\", since=\"2019-12-09\", until=\"2019-12-15\").items():\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 ['AlokSharma_RDG', 'Rehman_Chishti', 'BimAfolami', 'KwasiKwarteng', 'ShaileshVara', 'sajidjavid', 'HelenGrantMP', 'AlanMakHavant', 'JamesCleverly', 'SuellaBraverman', 'patel4witham', 'Nus_Ghani', 'nadhimzahawi', 'RishiSunak', 'KemiBadenoch', 'AdamAfriyie', 'ranil', 'JDjanogly', 'grantshapps', 'Michael_Ellis1', 'lucyfrazermp', 'Mike_Fabricant', 'ZacGoldsmith', 'VoteIvan', 'YasinForBedford', 'FaisalRashidMP', 'MarshadeCordova', 'Eleanor_SmithMP', 'Bambos4MP', 'PreetKGillMP', 'Valerie_VazMP', 'RupaHuq', 'DrRosena', 'TulipSiddiq', 'SeemaMalhotra1', 'labourlewis', 'YasminQureshiMP', 'TanDhesi', 'lisanandy', 'ChiOnwurah', 'khalid4PB', 'MpHendrick', 'JanetDaby', 'Imran_HussainMP', 'NazShahBfd', 'KateOsamor', 'VirendraSharma', 'ThangamMP', 'DawnButlerBrent', 'rushanaraali', 'HackneyAbbott', 'Afzal4Gorton', 'ShabanaMahmood', 'DavidLammy', 'SadiqKhan', 'Jeremy_Newmark', 'RuthSmeeth', 'FabianLeedsNE', 'alexsobel', 'Ed_Miliband', 'margarethodge', 'LaylaMoran', 'ChukaUmunna', 'SamGyimah', 'lucianaberger']\n",
      "AlokSharma_RDG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "Rehman_Chishti\n",
      "reached limit\n",
      "BimAfolami\n",
      "reached limit\n",
      "KwasiKwarteng\n",
      "reached limit\n",
      "ShaileshVara\n",
      "reached limit\n",
      "sajidjavid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "HelenGrantMP\n",
      "reached limit\n",
      "AlanMakHavant\n",
      "reached limit\n",
      "JamesCleverly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "SuellaBraverman\n",
      "reached limit\n",
      "patel4witham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "Nus_Ghani\n",
      "reached limit\n",
      "nadhimzahawi\n",
      "reached limit\n",
      "RishiSunak\n",
      "reached limit\n",
      "KemiBadenoch\n",
      "reached limit\n",
      "AdamAfriyie\n",
      "reached limit\n",
      "ranil\n",
      "reached limit\n",
      "JDjanogly\n",
      "reached limit\n",
      "grantshapps\n",
      "reached limit\n",
      "Michael_Ellis1\n",
      "reached limit\n",
      "lucyfrazermp\n",
      "reached limit\n",
      "Mike_Fabricant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "ZacGoldsmith\n",
      "reached limit\n",
      "VoteIvan\n",
      "reached limit\n",
      "YasinForBedford\n",
      "reached limit\n",
      "FaisalRashidMP\n",
      "reached limit\n",
      "MarshadeCordova\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "Eleanor_SmithMP\n",
      "reached limit\n",
      "Bambos4MP\n",
      "reached limit\n",
      "PreetKGillMP\n",
      "reached limit\n",
      "Valerie_VazMP\n",
      "reached limit\n",
      "RupaHuq\n",
      "reached limit\n",
      "DrRosena\n",
      "reached limit\n",
      "TulipSiddiq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "SeemaMalhotra1\n",
      "reached limit\n",
      "labourlewis\n",
      "reached limit\n",
      "YasminQureshiMP\n",
      "reached limit\n",
      "TanDhesi\n",
      "reached limit\n",
      "lisanandy\n",
      "reached limit\n",
      "ChiOnwurah\n",
      "reached limit\n",
      "khalid4PB\n",
      "reached limit\n",
      "MpHendrick\n",
      "reached limit\n",
      "JanetDaby\n",
      "reached limit\n",
      "Imran_HussainMP\n",
      "reached limit\n",
      "NazShahBfd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "KateOsamor\n",
      "reached limit\n",
      "VirendraSharma\n",
      "reached limit\n",
      "ThangamMP\n",
      "reached limit\n",
      "DawnButlerBrent\n",
      "reached limit\n",
      "rushanaraali\n",
      "reached limit\n",
      "HackneyAbbott\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 792\n",
      "Rate limit reached. Sleeping for: 812\n",
      "Rate limit reached. Sleeping for: 745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "Afzal4Gorton\n",
      "reached limit\n",
      "ShabanaMahmood\n",
      "reached limit\n",
      "DavidLammy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 801\n",
      "Rate limit reached. Sleeping for: 774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "SadiqKhan\n",
      "reached limit\n",
      "Jeremy_Newmark\n",
      "reached limit\n",
      "RuthSmeeth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "FabianLeedsNE\n",
      "reached limit\n",
      "alexsobel\n",
      "reached limit\n",
      "Ed_Miliband\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "margarethodge\n",
      "reached limit\n",
      "LaylaMoran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "ChukaUmunna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "SamGyimah\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n",
      "lucianaberger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached limit\n"
     ]
    }
   ],
   "source": [
    "accesstoken = '98886733-f5M5aYz2w3zivEILEHuFfvrDLXhYkYwL1xvgr9c9y'\n",
    "accesstokensecret = 'uOwbZGLE3WyevrWkKPaJu9rjtSY5IZJ3TE7pVJU8tp9ud'\n",
    "consumerkey = '2lWIAi4Z6UKKBxv33YTtpqilM'\n",
    "consumersecret = 'm7uNftueKNzg8LTG6s8WHDkMGII3DBXoXbbySnjzS0dHS6oTll'\n",
    " \n",
    "authorization = OAuthHandler(consumerkey, consumersecret)\n",
    "authorization.set_access_token(accesstoken, accesstokensecret)\n",
    "\n",
    "\n",
    "cons = get_hate_terms('./data/conservative.csv')\n",
    "ind = get_hate_terms('./data/independent.csv')\n",
    "labour =get_hate_terms('./data/labour.csv')\n",
    "lib_dem = get_hate_terms('./data/lib_dem.csv')\n",
    "\n",
    "terms = cons + ind + labour + lib_dem\n",
    "\n",
    "print(len(terms), terms)\n",
    "time_limit = 15 * 60\n",
    "jfile = open('./data/ua3.json', 'a')\n",
    "\n",
    "api = tweepy.API(authorization, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, retry_delay=5)\n",
    "for i in terms:\n",
    "    try:\n",
    "        c = tweepy.Cursor(api.search, q=i, count=100, lang=\"en\", \n",
    "                          since=\"2019-12-9\", \n",
    "                          until=\"2019-12-17\").items()\n",
    "        print(i)\n",
    "        start_time = time.time() \n",
    "        for tweet in c:\n",
    "            json.dump(tweet._json, jfile)\n",
    "            jfile.write(\"%s\"%'\\n')\n",
    "        if (time.time() - start_time) < time.time()+time_limit:\n",
    "            #print('------------sleeping for 10 seconds------------------')\n",
    "            print('reached limit')\n",
    "            time.sleep(3)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(e.__doc__) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
